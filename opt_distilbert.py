import os
os.environ["TOKENIZERS_PARALLELISM"] = "true"

import time
from datetime import datetime
from copy import deepcopy

import torch
from transformers import (
    AutoTokenizer, DistilBertForSequenceClassification,
    Trainer, TrainingArguments, DataCollatorWithPadding,
    EarlyStoppingCallback
)
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, f1_score
from datasets import Dataset, DatasetDict

# NEW
import optuna
import matplotlib.pyplot as plt

dataset = "dataset.csv"
dataset_path = "./datasets/" + dataset
epochs = 5
runname = f"opt_distil_{dataset}_epochs_{epochs}"
logging_dir=f"./logs/{runname}/"
output_dir=f"./results/{runname}/"
hpo_dir = os.path.join(output_dir, "hpo_artifacts")
os.makedirs(logging_dir, exist_ok=True)
os.makedirs(output_dir, exist_ok=True)
os.makedirs(hpo_dir, exist_ok=True)

print(dataset)

# Device (–¥–ª—è —ñ–Ω—Ñ–æ)
device = torch.device("mps" if torch.backends.mps.is_available() else
                      "cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")

# ‚ö° FAST tokenizer –∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–µ—à—É
local = "distilbert-base-multilingual-cased"
tokenizer = AutoTokenizer.from_pretrained(local, use_fast=True)

def model_init():
    return DistilBertForSequenceClassification.from_pretrained(
        local, local_files_only=True, num_labels=2
    )

print('start reading')
df = pd.read_csv(dataset_path)
print('end reading')

print('fill label start')
df['label'] = df['sent'].apply(lambda x: 1 if x + 1 >= 1 else 0)
print('end fill label')

print('train_test_split start')
train_df, val_df = train_test_split(df[['text','label']], test_size=0.2, random_state=42)
print('end train_test_split')

# üîÅ HF Datasets
train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))
val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))
raw = DatasetDict({"train": train_ds, "validation": val_ds})

# üöÄ –¢–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è
num_workers = 16
def tok(batch):
    return tokenizer(
        batch["text"],
        truncation=True,
        max_length=128,
    )

print('start tokenizer (multiprocessing map)')
tok_ds = raw.map(
    tok,
    batched=True,
    batch_size=2048,
    num_proc=num_workers,
    remove_columns=["text"],
)
print('end tokenizer')

# Collator
data_collator = DataCollatorWithPadding(
    tokenizer=tokenizer,
    pad_to_multiple_of=8
)

# –ú–µ—Ç—Ä–∏–∫–∏ (—Ç–µ–ø–µ—Ä —ñ accuracy, —ñ F1)
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    return {
        "accuracy": accuracy_score(labels, preds),
        "f1": f1_score(labels, preds, average="weighted"),
    }

# –ë–∞–∑–æ–≤—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è (–¥–µ—è–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –±—É–¥–µ –ø—ñ–¥–±–∏—Ä–∞—Ç–∏ Optuna)
base_args = TrainingArguments(
    output_dir=output_dir,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=epochs,            # –º–æ–∂–µ –±—É—Ç–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω–æ HPO
    per_device_train_batch_size=16,     # –º–æ–∂–µ –±—É—Ç–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω–æ HPO
    per_device_eval_batch_size=16,
    logging_dir=logging_dir,
    report_to=["tensorboard"],
    load_best_model_at_end=True,
    metric_for_best_model="f1",         # —Å—Ç–µ–∂–∏–º–æ –∑–∞ F1
    greater_is_better=True,
    seed=42,
    # fp16=True  # —è–∫—â–æ CUDA Ampere+; –∞–±–æ bf16=True —Ç–∞–º, –¥–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è
)

# --- –ü—ñ–¥–º–Ω–æ–∂–∏–Ω–∞ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ HPO (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏ –º–æ–∂–Ω–∞ –¥–∞—É–Ω—Å–µ–º–ø–ª–∏—Ç–∏)
train_for_hpo = tok_ds["train"]
eval_for_hpo  = tok_ds["validation"]

# --------- Optuna: –ø—Ä–æ—Å—Ç—ñ—Ä –ø–æ—à—É–∫—É ---------
def suggest_params(trial: optuna.Trial):
    return {
        "learning_rate": trial.suggest_float("learning_rate", 1e-5, 5e-4, log=True),
        "num_train_epochs": trial.suggest_int("num_train_epochs", 2, 6),
        "per_device_train_batch_size": trial.suggest_categorical("per_device_train_batch_size", [8, 16, 32]),
        "weight_decay": trial.suggest_float("weight_decay", 0.0, 0.15),
        "warmup_ratio": trial.suggest_float("warmup_ratio", 0.0, 0.2),
        "lr_scheduler_type": trial.suggest_categorical(
            "lr_scheduler_type", ["linear", "cosine", "cosine_with_restarts", "polynomial"]
        ),
        "gradient_accumulation_steps": trial.suggest_categorical("gradient_accumulation_steps", [1, 2, 4]),
    }

def objective(trial: optuna.Trial):
    # 1) —Å–∫–æ–ø—ñ—é–≤–∞—Ç–∏ –±–∞–∑–æ–≤—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ —ñ –∑–∞–ø–∏—Å–∞—Ç–∏ –ø—ñ–¥—ñ–±—Ä–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    args = TrainingArguments(**deepcopy(base_args.to_dict()))
    params = suggest_params(trial)
    for k, v in params.items():
        setattr(args, k, v)

    # 2) –ª–æ–∫–∞–ª—å–Ω–∏–π Trainer
    trainer = Trainer(
        model_init=model_init,
        args=args,
        train_dataset=train_for_hpo,
        eval_dataset=eval_for_hpo,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],
    )

    # 3) —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è + –æ—Ü—ñ–Ω–∫–∞
    trainer.train()
    metrics = trainer.evaluate()

    # 4) –∑–±–µ—Ä–µ–∂–µ–º–æ –æ–±–∏–¥–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∞—Ç—Ä–∏–±—É—Ç–∏ —Ç—Ä—ñ–∞–ª—É (–¥–ª—è CSV/–≥—Ä–∞—Ñ—ñ–∫—ñ–≤)
    # –º–µ—Ç—Ä–∏–∫–∏ —É Transformers –∑–∞–∑–≤–∏—á–∞–π –º–∞—é—Ç—å –∫–ª—é—á—ñ –≤–∏–¥—É "eval_f1" —ñ "eval_accuracy"
    eval_f1 = metrics.get("eval_f1", None)
    eval_acc = metrics.get("eval_accuracy", None)
    trial.set_user_attr("eval_f1", float(eval_f1) if eval_f1 is not None else None)
    trial.set_user_attr("eval_accuracy", float(eval_acc) if eval_acc is not None else None)

    # 5) –ø–æ–≤–µ—Ä—Ç–∞–π –º–µ—Ç—Ä–∏–∫—É-—Ü—ñ–ª—å (–æ–ø—Ç–∏–º—ñ–∑—É—î–º–æ F1)
    return eval_f1

# –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞ –∑–∞–ø—É—Å–∫–∞—î–º–æ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è
study = optuna.create_study(
    direction="maximize",
    sampler=optuna.samplers.TPESampler(seed=42),
    pruner=optuna.pruners.MedianPruner(n_warmup_steps=3),
)
n_trials = 20  # –∑–±—ñ–ª—å—à—É–π, —è–∫—â–æ —î —Ä–µ—Å—É—Ä—Å
print('start HPO')
hpo_start = time.time()
print(f"üïì HPO started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
study.optimize(objective, n_trials=n_trials, show_progress_bar=True)
hpo_end = time.time()
print(f"üèÅ HPO finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"‚è±Ô∏è HPO duration: {(hpo_end - hpo_start)/60:.2f} minutes")
print("Best params:", study.best_params)

# --------- CSV –∑ —É—Å—ñ–º–∞ —Ç—Ä—ñ–∞–ª–∞–º–∏ ---------
rows = []
for t in study.trials:
    row = {**t.params}
    row["trial_number"] = t.number
    row["value"] = t.value  # —Ü—ñ–ª—å–æ–≤–∞ –º–µ—Ç—Ä–∏–∫–∞ (F1)
    row["eval_f1"] = t.user_attrs.get("eval_f1")
    row["eval_accuracy"] = t.user_attrs.get("eval_accuracy")
    rows.append(row)

df_trials = pd.DataFrame(rows)

csv_path = os.path.join(hpo_dir, "hpo_trials.csv")
df_trials.to_csv(csv_path, index=False)
print(f"‚úÖ HPO trials saved: {csv_path}")

# --------- –ì—Ä–∞—Ñ—ñ–∫–∏: –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ ‚Äî –∑–Ω–∞—á–µ–Ω–Ω—è accuracy —Ç–∞ F1 ---------
def plot_metrics_vs_param(df, param, out_dir):
    # –ø—ñ–¥–≥–æ—Ç—É—î–º–æ x —Ç–∞ y
    x = df[param]
    y_f1 = df["eval_f1"]
    y_acc = df["eval_accuracy"]

    plt.figure()
    # –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ matplotlib –≤–º—ñ—î –º–∞–ª—é–≤–∞—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –Ω–∞–ø—Ä—è–º—É
    plt.scatter(x, y_f1, label="F1", marker="o")
    plt.scatter(x, y_acc, label="Accuracy", marker="x")
    plt.xlabel(param)
    plt.ylabel("Score")
    plt.title(f"Metrics vs {param}")
    plt.legend()
    plt.tight_layout()
    out_path = os.path.join(out_dir, f"metrics_vs_{param}.png")
    plt.savefig(out_path, dpi=150)
    plt.close()
    print(f"üìà Saved: {out_path}")

# –±—É–¥—É—î–º–æ —Å–ø–∏—Å–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∑ –∫–æ–ª–æ–Ω–∫–∏ DataFrame
param_cols = [c for c in df_trials.columns if c not in {"trial_number", "value", "eval_f1", "eval_accuracy"}]
for p in param_cols:
    plot_metrics_vs_param(df_trials, p, hpo_dir)

# --------- –§—ñ–Ω–∞–ª—å–Ω–µ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ---------
print('start training with best params')
train_start = time.time()
print(f"üïì Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

best_args = TrainingArguments(**{**base_args.to_dict(), **study.best_params})
final_trainer = Trainer(
    model_init=model_init,
    args=best_args,
    train_dataset=tok_ds["train"],
    eval_dataset=tok_ds["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],
)
final_trainer.train()

print('end training')
train_end = time.time()
elapsed = train_end - train_start
print(f"üèÅ Training finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"‚è±Ô∏è Training duration: {elapsed/60:.2f} minutes ({elapsed:.1f} seconds)")

final_metrics = final_trainer.evaluate()
print("Final eval:", final_metrics)

save_dir = f"./trained/opt_distilbert_{dataset}/"
final_trainer.save_model(save_dir)
tokenizer.save_pretrained(save_dir)
print(f"‚úÖ Saved model & tokenizer to: {save_dir}")
